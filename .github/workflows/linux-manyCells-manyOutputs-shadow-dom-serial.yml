name: Linux-manyCells-manyOutputs-shadow-dom-serial
on:
  # push: 
  # schedule:
  #   # * is a special character in YAML so you have to quote this string
  #   # Run every 6 hours.
  #   - cron:  '0 */6 * * *'
  workflow_dispatch:
jobs:
  linux:
    name: Linux
    runs-on: ubuntu-latest
    env:
      BROWSERS: '["chromium", "firefox"]'
      JLAB_HOME: '/home/runner/work/benchmarks/jupyterlab'
      JLAB_REPO: "https://github.com/jupyterlab/jupyterlab.git"
      # BENCHMARKS
      BENCHMARK_NOTEBOOKS: '["./manyCells", "./manyOutputs"]'
      BENCHMARK_MAX_N: ${{ matrix.BENCHMARK_MAX_N }}
      BENCHMARK_NUMBER_SAMPLES: ${{ matrix.BENCHMARK_NUMBER_SAMPLES }}
      BENCHMARK_SWITCHES: ${{ matrix.BENCHMARK_SWITCHES }}
      BENCHMARK_MAX_TIME: ${{ matrix.BENCHMARK_MAX_TIME }}
      # manyCells.ts
      CELLS_MULTIPLIER: ${{ matrix.CELLS_MULTIPLIER }}
      CODE_CELL_RATIO: ${{ matrix.CODE_CELL_RATIO }}
      # manyOutputs.ts
      MANY_OUTPUTS: ${{ matrix.MANY_OUTPUTS }}
    strategy:
      matrix:
        PYTHON: [3.8]
        NODEJS: [12.x]
        PLAYWRIGTH: ['1.0.2']
        JLAB_COMMITS_OLD: ['1f15fcb']
        JLAB_COMMITS_NEW: ['f7b7ee7']
        # JupyterLab [older-commit, newer-commit]
        # Benchmarks
        BENCHMARK_MAX_N: [100]          # Default is 100
        BENCHMARK_NUMBER_SAMPLES: [21]  # Default is 20
        BENCHMARK_SWITCHES: [10]
        BENCHMARK_MAX_TIME: [5000]      # Default is 5000
        # manyCells.ts
        CELLS_MULTIPLIER: [5]           # Default is 100
        CODE_CELL_RATIO: [0.9]          # Default is 0.9
        # manyOutputs.ts
        MANY_OUTPUTS: [100]             # Default is 100
      fail-fast: false
    timeout-minutes: 120
    steps:
      - name: Set up Python
        uses: actions/setup-python@v1
        with:
          python-version: ${{ matrix.PYTHON }}
      - name: Set up Node
        uses: actions/setup-node@v1
        with:
          node-version: ${{ matrix.NODEJS }}
      - name: Checkout benchmarks repository
        uses: actions/checkout@v2
      - name: Clone JupyterLab
        run: |
          cd ..
          git clone $JLAB_REPO
      - name: Build JupyterLab OLD revision
        run: |
          cd $JLAB_HOME
          git checkout ${{ matrix.JLAB_COMMITS_OLD }}
          pip install -e .
          jlpm install
          jlpm run build
      - name: Install playwright action
        uses: microsoft/playwright-github-action@v1
      - name: Install benchmarks
        run: |
          jlpm
          jlpm run build
      - name: Set BENCHMARK_OUTPUT for OLD
        run: echo "::set-env name=BENCHMARK_OUTPUT::${{ matrix.JLAB_COMMITS_OLD }}-manyCells-manyOutputs-${{ matrix.CELLS_MULTIPLIER }}-${{ matrix.CODE_CELL_RATIO }}-${{ matrix.MANY_OUTPUTS }}.csv"
      - name: Run benchmarks for OLD
        uses: GabrielBB/xvfb-action@v1.2
        with:
          run: jlpm ci
      - name: Remove notebook checkpoints and copy to artifacts folder
        run: |
          rm -rf packages/run/notebooks/.ipynb_checkpoints/
      - name: Upload OLD benchmark csv and notebook data artifacts
        uses: actions/upload-artifact@v2
        with:
          name: benchmarks_old
          path: |
            packages/run/*.csv
            packages/run/*.json
            packages/run/*.png
            packages/run/notebooks/
            !packages/run/analysis.vl.json
            !packages/run/comparison.vl.json
            !packages/run/package.json
            !packages/run/tsconfig.json
      - name: Clean benchmarks
        continue-on-error: true
        run: |
          rm -fr packages/run/notebooks
          rm packages/run/*.csv
          rm packages/run/*.png
      - name: Build JupyterLab NEW revision
        run: |
          cd $JLAB_HOME/..
          rm -fr jupyterlab
          git clone $JLAB_REPO
          cd $JLAB_HOME
          git checkout ${{ matrix.JLAB_COMMITS_NEW }} 
          pip install -e .
          jlpm install
          jlpm run build
      - name: Set BENCHMARK_OUTPUT for NEW
        run: echo "::set-env name=BENCHMARK_OUTPUT::${{ matrix.JLAB_COMMITS_NEW }}-manyCells-manyOutputs-${{ matrix.CELLS_MULTIPLIER }}-${{ matrix.CODE_CELL_RATIO }}-${{ matrix.MANY_OUTPUTS }}.csv"
      - name: Run benchmarks for NEW
        uses: GabrielBB/xvfb-action@v1.2
        with:
          run: jlpm ci
      - name: Remove notebook checkpoints and copy to artifacts folder
        run: |
          rm -rf packages/run/notebooks/.ipynb_checkpoints/
      - name: Upload NEW benchmark csv and notebook data artifacts
        uses: actions/upload-artifact@v2
        with:
          name: benchmarks_new
          path: |
            packages/run/*.csv
            packages/run/*.json
            packages/run/*.png
            packages/run/notebooks/
            !packages/run/analysis.vl.json
            !packages/run/comparison.vl.json
            !packages/run/package.json
            !packages/run/tsconfig.jso
  linux-compare:
    name: Linux
    runs-on: ubuntu-latest
    needs: linux
    env:
      OLD_KEY: 1f15fcb
      NEW_KEY: f7b7ee7
      KEY_TYPE: commit
    strategy:
      matrix:
        PYTHON: [3.8]
        NODEJS: [12.x]
      fail-fast: false
    timeout-minutes: 10
    steps:
      - name: Set up Python
        uses: actions/setup-python@v1
        with:
          python-version: ${{ matrix.PYTHON }}
      - name: Set up Node
        uses: actions/setup-node@v1
        with:
          node-version: ${{ matrix.NODEJS }}
      - name: Checkout benchmarks repository
        uses: actions/checkout@v2
      - name: Install compare tools
        run: |
          cd packages/compare
          npm install
      - name: List python dependencies
        run: pip list
      - name: List npm dependencies
        continue-on-error: true
        run: npm list --silent
      - name: Download the benchmark OLD data from previous jobs
        uses: actions/download-artifact@v2
        with:
          name: benchmarks_old
          path: packages/compare
      - name: Download the benchmark NEW data from previous jobs
        uses: actions/download-artifact@v2
        with:
          name: benchmarks_new
          path: packages/compare  
      - name: Check
        run: |
          cd packages/compare
          ls
      - name: Run compare python script
        run: |
          cd packages/compare
          python compare.py
      - uses: actions/upload-artifact@v2
        with:
          name: results
          path: |
            packages/compare/*.csv
            packages/compare/*.json
            packages/compare/*.vl.json
            packages/compare/*.png
            packages/compare/notebooks/*.ipynb
            !packages/compare/package.json
            !packages/compare/package-lock.json
            !packages/compare/tsconfig.json
